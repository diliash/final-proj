{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "device = \"cuda\"\n",
    "model_name = \"SenseTime/deformable-detr\"\n",
    "coco_folder='./partnetsim-1024-fixed-viewpoints/coco'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deformable-DETR has an unfortunate assumption in the code of labels being 0...N-1 for N labels. Therefore, some pre-processing is required as our labels start at 1. \n",
    "for split in [\"train\", \"val\"]:\n",
    "    ann_file = os.path.join(coco_folder, \"coco_annotation\", \"MotionNet_train.json\" if split==\"train\" else \"MotionNet_valid.json\")\n",
    "    with open(ann_file, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    for category in coco_data['categories']:\n",
    "        category['id'] -= 1\n",
    "    \n",
    "    modified_ann_file = os.path.join(coco_folder, \"coco_annotation\", 'modified_' + os.path.basename(ann_file))\n",
    "    with open(modified_ann_file, 'w') as f:\n",
    "        json.dump(coco_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(self, coco_folder, processor, train=True):\n",
    "        ann_file = os.path.join(coco_folder, \"coco_annotation\", \"modified_MotionNet_train.json\" if train else \"modified_MotionNet_valid.json\")\n",
    "        super(CocoDetection, self).__init__(os.path.join(coco_folder, \"train/origin\" if train else \"valid/origin\"), ann_file)\n",
    "        self.processor = processor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = super(CocoDetection, self).__getitem__(idx)\n",
    "        image_id = self.ids[idx]\n",
    "        \n",
    "        modified_target = []\n",
    "        for annotation in target:\n",
    "            annotation['category_id'] -= 1\n",
    "            modified_target.append(annotation)\n",
    "        \n",
    "        target = {'image_id': image_id, 'annotations': modified_target}\n",
    "        encoding = self.processor(images=img, annotations=target, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
    "        target = encoding[\"labels\"][0]\n",
    "        return pixel_values, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from transformers import DeformableDetrImageProcessor\n",
    "\n",
    "processor = DeformableDetrImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "train_dataset = CocoDetection(coco_folder='./partnetsim-1024-fixed-viewpoints/coco', processor=processor)\n",
    "val_dataset = CocoDetection(coco_folder='./partnetsim-1024-fixed-viewpoints/coco', processor=processor, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = train_dataset.coco.cats\n",
    "id2label = {k: v['name'] for k,v in cats.items()}\n",
    "label2id = {v: k for k,v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "  pixel_values = [item[0] for item in batch]\n",
    "  encoding = processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "  labels = [item[1] for item in batch]\n",
    "  batch = {}\n",
    "  batch['pixel_values'] = encoding['pixel_values']\n",
    "  batch['pixel_mask'] = encoding['pixel_mask']\n",
    "  batch['labels'] = labels\n",
    "  return batch\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=4, shuffle=True, pin_memory=True, prefetch_factor=4, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=collate_fn, batch_size=1, pin_memory=True, prefetch_factor=4, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from transformers import DeformableDetrForObjectDetection\n",
    "import torch\n",
    "\n",
    "class DeformableDetr(pl.LightningModule):\n",
    "   def __init__(self, lr, lr_backbone, weight_decay, id2label, label2id):\n",
    "      super().__init__()\n",
    "      self.model = DeformableDetrForObjectDetection.from_pretrained(model_name,\n",
    "                                                            num_labels=len(id2label),\n",
    "                                                            id2label=id2label,\n",
    "                                                            ignore_mismatched_sizes=True)\n",
    "      self.model = self.model.to(device)\n",
    "      self.lr = lr\n",
    "      self.lr_backbone = lr_backbone\n",
    "      self.weight_decay = weight_decay\n",
    "\n",
    "   def forward(self, pixel_values, pixel_mask):\n",
    "      outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "      return outputs\n",
    "\n",
    "   def common_step(self, batch, batch_idx):\n",
    "      pixel_values = batch[\"pixel_values\"]\n",
    "      pixel_mask = batch[\"pixel_mask\"]\n",
    "      labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "      outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
    "\n",
    "      loss = outputs.loss\n",
    "      loss_dict = outputs.loss_dict\n",
    "\n",
    "      return loss, loss_dict\n",
    "\n",
    "   def training_step(self, batch, batch_idx):\n",
    "      loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "      self.log(\"training_loss\", loss)\n",
    "      for k,v in loss_dict.items():\n",
    "         self.log(\"train_\" + k, v.item())\n",
    "\n",
    "      return loss\n",
    "\n",
    "   def validation_step(self, batch, batch_idx):\n",
    "      loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "      self.log(\"validation_loss\", loss)\n",
    "      for k,v in loss_dict.items():\n",
    "         self.log(\"validation_\" + k, v.item())\n",
    "      return loss\n",
    "\n",
    "   def configure_optimizers(self):\n",
    "      param_dicts = [\n",
    "            {\"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "            {\n",
    "               \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "               \"lr\": self.lr_backbone,\n",
    "            },\n",
    "      ]\n",
    "      optimizer = torch.optim.AdamW(param_dicts, lr=self.lr,\n",
    "                                 weight_decay=self.weight_decay)\n",
    "\n",
    "      return optimizer\n",
    "\n",
    "   def train_dataloader(self):\n",
    "      return train_dataloader\n",
    "\n",
    "   def val_dataloader(self):\n",
    "      return val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for GPUs with tensor cores\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"DeformableDETR-pl-finetune\")\n",
    "\n",
    "dirpath = f\"checkpoints/DeformableDETR/{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "os.makedirs(dirpath, exist_ok=True)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=dirpath,\n",
    "    filename=\"deformable-detr-{epoch:02d}\",\n",
    "    save_top_k=-1,\n",
    "    every_n_epochs=5,\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "hparams = {\"checkpoints_path\": dirpath, \n",
    "           \"lr\": 1e-5, \n",
    "           \"lr_backbone\": 1e-5, \n",
    "           \"weight_decay\": 1e-3, \n",
    "           \"id2label\": id2label, \n",
    "           \"label2id\": label2id, \n",
    "           \"max_steps\": 3000, \n",
    "           \"gradient_clip_val\": 0.2, \n",
    "           \"accelerator\": device, \n",
    "           \"devices\": 1, \n",
    "           \"batch_size\": 4, \n",
    "           \"model_name\": model_name}\n",
    "\n",
    "model = DeformableDetr(lr=hparams[\"lr\"], lr_backbone=hparams[\"lr_backbone\"], weight_decay=hparams[\"weight_decay\"], id2label=id2label, label2id=label2id).to(device)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_steps=hparams[\"max_steps\"],\n",
    "    gradient_clip_val=hparams[\"gradient_clip_val\"],\n",
    "    logger=wandb_logger,\n",
    "    accelerator=device,\n",
    "    devices=hparams[\"devices\"],\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "wandb_logger.log_hyperparams(hparams)\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.push_to_hub(f\"diliash/deformable-detr-{dirpath.split('/')[-1]}\")\n",
    "processor.push_to_hub(f\"diliash/deformable-detr-{dirpath.split('/')[-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
